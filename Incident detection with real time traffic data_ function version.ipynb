{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic incident detection with real time traffic data \n",
    "\n",
    "Incidents on highways can significantly affect the road capacity and decrease the reliability of the highway system. This project proposes a tool for incident detection, which solely utilizes data from traffic counters and could therefore provide an alternative solution in regions where sensors and cameras are limited. The occurrence of incidents on the network typically causes delay and reduction in traffic volume, which is recorded by traffic counters and reflected in real-time traffic data. In this research, we develop an algorithm that uses Machine Learning Gaussian Process regression to extract the average traffic flow parameters and identifies anomalous data with a statistical approach. \n",
    "\n",
    "In order to test the precision and recall of the algorithm, we examined the correlation between anomalous data and incident records and built a proof-of-concept model with traffic data from a segment of the M1 motorway. \n",
    "\n",
    "\n",
    "There are five main parts of the this notebook\n",
    "* Data processing\n",
    "* Model trainning\n",
    "* Anomoly detection\n",
    "* Anomoly filtering\n",
    "* Precision and Recall Calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 import traffic counter data and incident detection data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import traffic counter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfFile=[\"190115.tcd.csv\",\"190122.tcd.csv\",\"190129.tcd.csv\",\"190205.tcd.csv\",\"190212.tcd.csv\",\"190219.tcd.csv\",\n",
    "\"190226.tcd.csv\",\"190305.tcd.csv\",\"190312.tcd.csv\",\"190319.tcd.csv\",\"190402.tcd.csv\",\"190409.tcd.csv\",\"190416.tcd.csv\",\n",
    "\"190423.tcd.csv\",\"190430.tcd.csv\",\"190507.tcd.csv\",\"190514.tcd.csv\",\"190521.tcd.csv\",\"190528.tcd.csv\",\"190604.tcd.csv\",\n",
    "\"190611.tcd.csv\",\"190618.tcd.csv\",\"190625.tcd.csv\",\"190702.tcd.csv\",\"190709.tcd.csv\",\"190716.tcd.csv\",\"190723.tcd.csv\",\n",
    "\"190730.tcd.csv\",\"190813.tcd.csv\",\"190820.tcd.csv\",\"190827.tcd.csv\",\"190903.tcd.csv\",\"190910.tcd.csv\",\"190917.tcd.csv\",\n",
    "\"190924.tcd.csv\",\"191001.tcd.csv\",\"191008.tcd.csv\",\"191022.tcd.csv\",\"191029.tcd.csv\",\"191105.tcd.csv\",\"191112.tcd.csv\",\n",
    "\"191119.tcd.csv\",\"191203.tcd.csv\",\"191210.tcd.csv\",\"191217.tcd.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_flow_yearly=None\n",
    "for i in range(len(listOfFile)):\n",
    "    df = pd.read_csv(listOfFile[i])\n",
    "    #for traffic counter M1/2393A\n",
    "    df_2393A=df.iloc[0:1440]\n",
    "    a=df_2393A.loc[:,'Flow(Lane 1)'].to_numpy()\n",
    "    b=df_2393A.loc[:,'Flow(Lane 2)'].to_numpy()\n",
    "    c=df_2393A.loc[:,'Flow(Lane 3)'].to_numpy()\n",
    "    d=df_2393A.loc[:,'Flow(Lane 4)'].to_numpy()\n",
    "    sum_flow_daily=a+b+c+d\n",
    "    if sum_flow_yearly is None:\n",
    "        sum_flow_yearly=sum_flow_daily\n",
    "    else:\n",
    "        sum_flow_yearly=np.vstack((sum_flow_yearly,sum_flow_daily))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import incident records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_data = pd.read_excel ('incident records.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_data = pd.DataFrame(inc_data)\n",
    "inc_data_tue = inc_data[(inc_data['Day_of_week'] == 'Tuesday') & (inc_data['Northing'] < 219789)& (inc_data['Northing'] > 205973)]\n",
    "inc_data_sim = inc_data_tue.loc[:,'Minute_of_hour':'Month_of_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "increc_hour=inc_data_sim.loc[:,'Hour_of_day'].to_numpy()\n",
    "increc_day=inc_data_sim.loc[:,'Day_of_month'].to_numpy()\n",
    "increc_month=inc_data_sim.loc[:,'Month_of_year'].to_numpy()\n",
    "increc_mins=inc_data_sim.loc[:,'Minute_of_hour'].to_numpy()\n",
    "datasum=[]\n",
    "for i in range(len(increc_hour)):\n",
    "    if len(str(increc_day[i]))==1:\n",
    "        increc_day_str='0'+str(increc_day[i])\n",
    "    else:\n",
    "        increc_day_str=str(increc_day[i])\n",
    "    data=str(increc_month[i])+increc_day_str\n",
    "    datasum.append(data)\n",
    "increctime=increc_hour+increc_mins/60\n",
    "# convert the data into a comparable format\n",
    "increc_date=np.transpose([datasum,increctime])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot of traffic counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacondensing(orginal,compactingfactor):\n",
    "    a= orginal.shape[1]\n",
    "    mergedsize=int(a/compactingfactor)\n",
    "    newdataset=None\n",
    "    if a%compactingfactor==0:\n",
    "        for i in range (mergedsize):\n",
    "            mergeddata=np.sum(orginal[:,compactingfactor*(i):compactingfactor*(i+1)], axis=1)\n",
    "            if newdataset is None:\n",
    "                newdataset=mergeddata\n",
    "            else:\n",
    "                newdataset=np.vstack((newdataset,mergeddata))\n",
    "        return (newdataset.transpose())\n",
    "    else:\n",
    "        print ('ERROR! aliquant, please choose a factor of 1440')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(dataset,compactingfactor):\n",
    "    dataset=datacondensing(dataset,compactingfactor)\n",
    "    for i in range (len(dataset)):\n",
    "        x=np.linspace(0,int(1440/(compactingfactor)),int(1440/(compactingfactor)))/(60/compactingfactor)\n",
    "        dailyflow=dataset[i,:]\n",
    "        plt.plot(x,dailyflow,'.')\n",
    "    plt.xlabel('Hours in a day', fontsize=18)\n",
    "    plt.ylabel('Traffic volumn per '+str(compactingfactor)+' min ', fontsize=16)\n",
    "    plt.xlim(0, 24) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_to_nan(values):\n",
    "    \"\"\"Replace every 0 with 'nan' and return a copy.\"\"\"\n",
    "    return [float('nan') if x==0 else x for x in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleGDforanomolies(dataset,compactingfactor):\n",
    "    dataset=datacondensing(dataset,compactingfactor)\n",
    "    Mu=np.mean(dataset,axis=0)\n",
    "    var=np.var(dataset,axis=0)\n",
    "    lower_limite=Mu-2*np.sqrt(var)\n",
    "    upper_limite=Mu+2*np.sqrt(var)\n",
    "    anom_year=None\n",
    "    x=np.linspace(0,int(1440/(compactingfactor)),int(1440/(compactingfactor)))/(60/compactingfactor)\n",
    "    for i in range (len(dataset)):\n",
    "        dailyflow=dataset[i,:]\n",
    "        anom_day=(dailyflow<lower_limite).astype(int)\n",
    "        if anom_year is None:\n",
    "            anom_year=anom_day\n",
    "        else:\n",
    "            anom_year=np.vstack((anom_year,anom_day))\n",
    "    for i in range (len(dataset)):\n",
    "        dailyflow=dataset[i,:]\n",
    "        #plt.plot(dailyflow,'.')\n",
    "        anomonly=dailyflow*anom_year[i,:]\n",
    "        plt.plot(x,zero_to_nan(anomonly),'.')\n",
    "    plt.plot(x,lower_limite,color='black')\n",
    "    plt.plot(x,upper_limite,color='black')\n",
    "    plt.plot(x,Mu,color='black')\n",
    "    plt.xlabel('Hours in a day', fontsize=18)\n",
    "    plt.xlim(0, 24) \n",
    "    plt.ylabel('Traffic volumn per '+str(compactingfactor)+' min ', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anom_filter (value,threshold):\n",
    "    # imputs are boolean of function and threshold value\n",
    "    tot=0\n",
    "    threholded=np.zeros(value.shape)\n",
    "    for i in range(len(value)):\n",
    "        if value[i]==0:\n",
    "            tot=tot*value[i]\n",
    "        else:\n",
    "            tot=tot+value[i]\n",
    "        if tot==threshold:\n",
    "            threholded[i]=1\n",
    "            tot=0\n",
    "    return threholded\n",
    "    anom_year=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getthelistofanomalies(value):\n",
    "    list_det_= None\n",
    "    time_list=np.asarray(np.nonzero(value))\n",
    "    #print (\"total number of anomolies detected: \",time_list.shape[1])\n",
    "    for i in range (time_list.shape[1]):\n",
    "        date_detected=listOfFile[time_list[0,i]].split('.')[0]\n",
    "        day=date_detected[2]+date_detected[3]+date_detected[4]+date_detected[5]\n",
    "        time=time_list[1,i]/60;\n",
    "        inc_detected=[int(day),time]\n",
    "        if list_det_ is None:\n",
    "            list_det_=inc_detected\n",
    "        else:\n",
    "            list_det_=np.vstack((list_det_,inc_detected))\n",
    "    return list_det_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision (detected, records):\n",
    "    \n",
    "    FP=0\n",
    "    error=0.5\n",
    "    for i in range(len(detected)):\n",
    "        datefinding=np.where(records[:,0] == str(int(detected[i,0])))\n",
    "        datefinding=np.asarray(datefinding)\n",
    "        #print(type(datefinding))\n",
    "        #print(datefinding)\n",
    "        is_empty = datefinding.size == 0\n",
    "        if is_empty:\n",
    "            #print(\"incident record\", i, \"nothing matches\")\n",
    "            FP=FP+1\n",
    "        else:\n",
    "            timeinfounddata=np.array([])\n",
    "            for j in range(records[datefinding,1].shape[1]):\n",
    "                whattime = float(records[datefinding,1][0,j])\n",
    "                timeinfounddata=np.append(timeinfounddata,whattime)\n",
    "            timefinding=np.where(np.logical_and(timeinfounddata>=detected[i,1]-error,timeinfounddata<=detected[i,1]+error))\n",
    "            timefinding=np.asarray(timefinding)\n",
    "            is_time_empty = timefinding.size == 0\n",
    "            if is_time_empty:\n",
    "                #print(\"incident record\", i,\"nothing matches\")\n",
    "                FP=FP+1\n",
    "            #else:\n",
    "                #print(\"incident record\", i,detected[i,1],\"found matched value\", \"time is:\",timeinfounddata[timefinding]  )\n",
    "    \n",
    "    precision=1-FP/len(detected)\n",
    "    \n",
    "    return precision\n",
    "    #print (\"precision rate is:\", 1-FP/len(detected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotfilterreddata(dataset,threshold,compactingfactor,records):\n",
    "    value=datacondensing(dataset,compactingfactor)\n",
    "    Mu=np.mean(value,axis=0)\n",
    "    var=np.var(value,axis=0)\n",
    "    lower_limite=Mu-2*np.sqrt(var)\n",
    "    upper_limite=Mu+2*np.sqrt(var)\n",
    "    anom_year = None\n",
    "    x=np.linspace(0,int(1440/(compactingfactor)),int(1440/(compactingfactor)))/(60/compactingfactor)\n",
    "    for i in range (len(value)):\n",
    "        dailyflow=value[i,:]\n",
    "        anom_day= anom_filter((dailyflow<lower_limite).astype(int),threshold)\n",
    "        if anom_year is None:\n",
    "            anom_year=anom_day\n",
    "        else:\n",
    "            anom_year=np.vstack((anom_year,anom_day))\n",
    "    for i in range (len(value)):\n",
    "        dailyflow=value[i,:]\n",
    "        anomonly=dailyflow*anom_year[i,:]\n",
    "        '''\n",
    "        plt.plot(x,zero_to_nan(anomonly),'.')\n",
    "    plt.plot(x,lower_limite,color='black')\n",
    "    plt.plot(x,upper_limite,color='black')\n",
    "    plt.plot(x,Mu,color='black')\n",
    "    plt.xlim(0, 24)\n",
    "    plt.xlabel('mins in a day', fontsize=18)\n",
    "    plt.ylabel('Traffic volumn per '+str(compactingfactor)+' min ', fontsize=16)\n",
    "    plt.show()\n",
    "    '''\n",
    "    detectedanomalies=getthelistofanomalies(anom_year)\n",
    "    pre=precision (detectedanomalies, records)\n",
    "    return(pre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07999999999999996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotfilterreddata(sum_flow_yearly,4,5,increc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[1,2,3,4,5,6,10,15]\n",
    "Y=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=np.zeros((len(X), len(Y)))\n",
    "for i in range (len(X)):\n",
    "    for j in range (len(Y)):\n",
    "        Z[i,j]=plotfilterreddata(sum_flow_yearly,Y[j],X[i],increc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6486486486486487"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
